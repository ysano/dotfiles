# AI-DLCを前提としたスクラムイベントの再定義

AI駆動開発ライフサイクル（AI-DLC）において、従来のスクラムイベントは「人間同士の同期・コミュニケーション最適化」から「人間とAIエージェントの協働・検証最適化」へとパラダイムシフトする必要があります。2025年のScrum Guide Expansion Packでも、AIの統合がスクラムの各イベントに影響を与えることが公式に認識されています。\[^1\]\[^2\]

以下では、レポートで提示された「ケンタウロス・ポッド」「アトミック・スペック」「エージェント・ループ」の概念を踏まえ、4つのスクラムイベント＋スプリントそのものの再定義を詳述します。

---

## スプリントサイクルそのもの：2週間から「マイクロスプリント」へ

### ボトルネックの移動が周期を変える

AI駆動開発において最も根本的な変化は、**開発サイクルの劇的な圧縮**です。AIエージェントがコーディング・テスト・リファクタリングを高速で処理できるようになった結果、従来2週間が標準だったスプリントは人為的なボトルネックになりつつあります。\[^3\]\[^4\]

「コンセプト→コード→テスト→デプロイ」のサイクルがAIによって劇的に圧縮された今、2週間スプリントは人工的なボトルネックである——という指摘が複数の実務家から上がっています。\[^5\]\[^6\]

### 推奨される新サイクル

| チームスケール | 推奨スプリント長 | 理由 |
| :---- | :---- | :---- |
| **ケンタウロス・ポッド（1〜10名）** | 1〜3日（マイクロスプリント）またはカンバン型連続フロー | コンテキスト密度が高く、AIが1日で複数PRを生成可能。日次デモが現実的\[^3\]\[^6\] |
| **エージェンティック・スクワッド（10〜30名）** | 3〜5日 | チーム間調整が必要なため完全な日次は困難。ただし週単位に短縮可能\[^5\] |
| **エンタープライズ（30名以上）** | 1週間 | ガバナンス・コンプライアンスレビューの時間を確保しつつ、従来の半分に圧縮\[^1\] |

ただし、Scrum Guide Expansion Pack（2026年1月版）は重要な警告を発しています。**AIは出力を加速させるが、成果（アウトカム）を自動的に保証するわけではない**。スプリントを短縮しても、ユーザー検証やステークホルダーフィードバックの質が伴わなければ「間違ったものをより速く作る」だけになります。\[^1\]

---

## スプリントプランニング：「人間の合議」から「AIシミュレーション＋人間の承認」へ

### 従来の問題

従来のスプリントプランニングは2〜4時間の会議で、チームが「何をどれだけ引き受けるか」を議論・合意するイベントでした。見積もりは主に直感とチームの記憶に依存していました。

### AI-DLCにおける再定義

AI-DLCでは、プランニングは**3つのフェーズ**に分解されます。

#### フェーズ1：AIプリプランニング（非同期・自動）

プランニングミーティングの**前に**、AIエージェントが以下を自動実行します：\[^7\]\[^8\]

- **見積もりエージェント**が過去のストーリー複雑度・手戻り頻度・チームベロシティを分析し、実工数に基づく時間帯を提案  
- **依存関係エージェント**がクロスチーム間のブロッカーをスプリントバックログに入る前に検出  
- **優先度エージェント**がビジネスの緊急度と技術的実現可能性を整合させ、スコープ変更の波及効果をシミュレーション  
- **キャパシティ分析**でPTO・技術的負債レベルを考慮した現実的なイテレーション目標を算出\[^9\]

レポートの「アトミック・スペック」の概念がここで活きます。AIはバックログの各アイテムが「単一コンテキストウィンドウで完結するサイズか」「5つの構成要素（背景・現状・あるべき姿・制約・検証方法）が揃っているか」を自動検証し、不備があればSpec Definitionステータスに戻します。

#### フェーズ2：人間の戦略的判断（同期・短時間）

AIの分析結果を受けて、人間が**30分〜1時間**で以下を決定します：\[^5\]

- AIが提案したスプリントスコープの承認または修正  
- **「何をAIに任せるか」「何を人間が直接実装するか」の判断**——これは従来のプランニングには存在しなかった新しい論点\[^1\]  
- AI出力の検証に充てる時間の明示的な確保  
- ハイリスク領域（セキュリティ、アーキテクチャ変更）の人間レビュー方針

Scrum Guide Expansion Packが指摘するように、「AIが作れるか」ではなく「**作るべきか（そしてなぜか）**」がプランニングの中心的な問いになります。\[^1\]

#### フェーズ3：エージェントへのタスク配信

承認後、Claude Codeのticket-managerスキルやMCP連携を通じて、各チケットが自動的にAIエージェントに配信されます。レポートのステータス遷移モデルでは、この段階で「AI Planning」→「AI Implementation」への遷移が始まります。

### 従来との比較

| 観点 | 従来のスプリントプランニング | AI-DLCのスプリントプランニング |
| :---- | :---- | :---- |
| 所要時間 | 2〜4時間 | 30分〜1時間（AI事前分析＋人間承認）\[^5\] |
| 見積もり手法 | プランニングポーカー（直感ベース） | AIによるヒストリカルデータ分析＋シミュレーション\[^8\] |
| 主な議論 | 「誰が何をやるか」「どう実装するか」 | 「作るべきか」「AIに任せるか人間がやるか」「検証をどう設計するか」\[^1\] |
| スコープ決定 | チームの主観的キャパシティ感覚 | AI予測ベロシティ vs 実キャパシティの定量比較\[^9\] |

---

## デイリースクラム：「同期ステータス報告」から「非同期AIダイジェスト＋判断フォーカスセッション」へ

### 従来の問題

15分のスタンドアップが45分に膨張し、同じブロッカーが繰り返し報告され、解決に至らない——これは多くのチームが経験する問題です。\[^10\]

### AI-DLCにおける再定義

デイリースクラムは**2層構造**に分解されます。

#### 層1：AIダイジェスト（非同期・自動生成）

毎朝（または設定したタイミングで）、AIエージェントが以下を自動コンパイルしてSlack/Teamsに投稿します：\[^8\]\[^10\]

- **前日のコミット・PR活動**の要約  
- **スプリント進捗 vs ベロシティトレンド**のリアルタイム比較  
- **ブロッカー検出**：ワークフローの停滞やセンチメント分析による問題の早期発見  
- **AIエージェントの活動報告**：どのチケットがAI Implementationステータスにあり、どれが4時間ルールに抵触しそうか（レポートの「AIジャニター」機能と連動）  
- **未マージPR・レビューボトルネック**の可視化

この非同期ダイジェストにより、ステータス報告の**70%が自動化**されるという報告があります。\[^10\]

#### 層2：人間の判断セッション（同期・超短時間）

AIダイジェストを前提として、人間が**5〜10分**で以下に集中します：

- **AIが解決できないブロッカー**の議論と意思決定  
- **AIエージェントの出力品質**に関する懸念の共有（ハルシネーション検出報告など）  
- **人間介入が必要なチケット**の優先度調整（4時間ルールでエスカレーションされたもの）  
- **クロスチーム依存関係**の人間同士での調整

40名以上の分散チームでは、同期スタンドアップを完全に非同期AIダイジェストに置き換え、週あたり5〜7時間を回収した事例も報告されています。\[^11\]

### 重要な設計原則

デイリースクラムにおけるAI統合で最も注意すべきは「**儀式の空洞化（Ritual Hollowing）**」です。AIが自動化しすぎると、チームメンバーが自分たちのプロセスから心理的に離脱するリスクがあります。Scrum Guide Expansion Packは「AIは儀式を補強するが、チームの存在や省察を代替してはならない」と明確に述べています。\[^8\]\[^1\]

---

## スプリントレビュー：「デモ会」から「AI出力の検証・ステークホルダー実験セッション」へ

### 従来の問題

従来のスプリントレビューは、チームがスプリントで作ったものをステークホルダーにデモする場でした。しかしAI-DLCでは、デモすべき成果物の量が爆発的に増える一方、「それが本当に正しいか」の検証が最大の課題になります。

### AI-DLCにおける再定義

#### 3つの新しい焦点

**1\. AI生成物の品質検証**

レビューの中心テーマは「何を作ったか」から「**AIが作ったものは正しいか**」にシフトします。Scrum Guide Expansion Packは、スプリントレビューを拡張して「何を作ったかだけでなく、**AIでどう作ったか**、そこからどんな問題や学びが生まれたか」を検査すべきとしています。\[^1\]

具体的には：

- AIエージェントが自動生成したPRの**ビジュアルdiff**とシステム変更の可視化\[^8\]  
- コードデリバリーとユーザーストーリーの**トレーサビリティマッピング**  
- テストカバレッジの変化と**AI-Confidenceスコア**（レポートのカスタムフィールド）のレビュー

**2\. 高速仮説検証**

AIが機能を高速で生成できるようになったことで、「最小限の実装を数日でユーザーに試してもらう」ことが現実的になります。プロダクトオーナーはAI加速された速度を活用して、仮説をより早く・頻繁に検証すべきです。レビューは「完成品の披露」ではなく「**実験結果の共有と次の仮説の設定**」の場になります。\[^1\]

**3\. Definition of Outcome Done（成果完了定義）の検査**

レポートのDoDに加え、Scrum Guide Expansion Packは\*\*2種類の「Done」\*\*を区別しています：\[^1\]

- **Definition of Output Done**：動くソフトウェアとしての品質基準（テスト・レビュー・セキュリティ）  
- **Definition of Outcome Done**：ビジネスインパクトの基準（「この変更がユーザー行動・体験・結果を改善した証拠は何か？」）

AIが生産量を増大させる環境では、Output Doneだけでなく**Outcome Doneの検査がレビューの最重要アジェンダ**になります。

### レビュー頻度の変化

マイクロスプリント（1〜3日）を採用する場合、正式なスプリントレビューを毎回行うのは非現実的です。代替として：

- **日次の軽量デモ**（15分、AIが自動生成したデモ資料を使用）\[^6\]  
- **週次の正式レビュー**（ステークホルダー参加、仮説検証結果の共有）  
- **月次のストラテジックレビュー**（プロダクト戦略レベルの方向性検証）

---

## スプリントレトロスペクティブ：「感想共有会」から「データ駆動型診断セッション」へ

### 従来の問題

レトロスペクティブは「グラウンドホッグ・デー（同じことの繰り返し）」になりがちで、同じ議論が繰り返され、アクションアイテムが実行されないという構造的な問題を抱えていました。\[^10\]

### AI-DLCにおける再定義

#### Before：AIによるスプリント診断レポート生成

レトロスペクティブの**前に**、AIエージェントが以下を自動生成します：\[^10\]\[^8\]

- **ベロシティトレンド**の可視化と完了/未完了ストーリーポイントの分析  
- **品質メトリクス**：バグ密度、技術的負債の増減、テストカバレッジ変化  
- **時間配分の内訳**：コーディング/レビュー/デバッグ/会議の比率  
- **チームセンチメント分析**：コミュニケーションのトーン・リアクションデータから推定\[^8\]  
- **インタラクション・チャーン分析**：レポートで定義された「1チケット完了に必要なプロンプト往復回数」の統計。3回以上の往復が発生したチケットの一覧と原因分析

#### During：人間主導の診断と意思決定

AIが提供するデータを基盤としつつ、**人間が主導して**以下を議論します：\[^8\]

- **AIエージェントの有効性評価**：「AIは今スプリントで助けになったか、邪魔になったか」——これは従来のレトロにはなかった新しい検査項目\[^1\]  
- **スペック品質の振り返り**：インタラクション・チャーンが高かったチケットの原因分析（粒度が大きすぎたか、仕様が曖昧だったか）  
- **CLAUDE.md・SKILLの改善提案**：エージェントが繰り返し間違えるパターンを特定し、プロジェクト憲法やスキル定義を更新する具体的なアクション  
- **過去のレトロアクションの効果測定**：AIが過去のアクションアイテムと今スプリントの成果の相関を分析\[^10\]

#### After：AIによるアクションアイテムの追跡と実行

レトロで合意されたアクションアイテムは自動的にチケット化され、次スプリントのバックログに投入されます。AIジャニターが実行状況を追跡し、未着手のものを次回レトロ前にリマインドします。

### 従来との比較

| 観点 | 従来のレトロスペクティブ | AI-DLCのレトロスペクティブ |
| :---- | :---- | :---- |
| データソース | チームの記憶と主観 | AIが生成した定量的スプリント診断レポート\[^10\]\[^8\] |
| 新しい検査項目 | なし | AIエージェントの有効性・CLAUDE.md/SKILLの改善・スペック品質\[^1\] |
| パターン認識 | 人間の直感 | AIによるスプリント横断のトレンド分析（繰り返されるブロッカー、センチメントと成果の相関）\[^10\] |
| アクションアイテム完了率 | 約60% | AI追跡により約92%に改善\[^10\] |
| ファシリテーション | 人間のみ | AIがテーマクラスタリング・データ提供、人間が意思決定\[^9\] |

レトロスペクティブに関する核心的な原則として、Ideas2ITは次のように述べています：「レトロをもはや記憶で行わない。AIがコミュニケーショントレンド、デリバリーボトルネック、未解決課題をスプリント全体にわたってマッピングし——データを持って会議室に入る、意見ではなく」。\[^8\]

---

## 新たに追加すべきイベント：「エージェント・キャリブレーション」

従来のスクラムには存在しなかった、AI-DLC固有の新イベントとして「**エージェント・キャリブレーション**」を提案します。

### 目的

AIエージェントの動作品質・CLAUDE.md・SKILL定義・Hooks設定を定期的に検査・調整する専用セッション。

### 頻度と参加者

- **頻度**：2週間に1回（マイクロスプリント採用時でも、この頻度で十分）  
- **参加者**：シニアアーキテクト＋ARE（AIリライアビリティエンジニア）＋プラットフォームチーム代表

### アジェンダ

1. **AI-Confidenceスコアの分布分析**：80未満が頻出するタスクカテゴリの特定と対策  
2. **ハルシネーション発生パターン**の共有とCLAUDE.mdへの禁止事項追加  
3. **Hooksの有効性レビュー**：ブロックされたコマンドのログ分析、新たに追加すべきガードレールの検討  
4. **サブエージェントの権限調整**：@planner/@coder/@reviewerの権限スコープが適切かの検証  
5. **SKILLライブラリの更新**：新たに頻出するタスクパターンのSKILL化

---

## 総括：スクラムイベント再定義の設計原則

AI-DLCにおけるスクラムイベント再定義は、以下の5つの設計原則に基づきます。

1. **検証シフト**：全イベントの重心を「作業の計画・報告」から「AI出力の検証・承認」へ移動させる\[^1\]  
2. **非同期ファースト**：AIが自動化できるステータス共有・データ分析は非同期化し、同期の時間は人間にしかできない判断・創造・関係構築に集中させる\[^11\]  
3. **データ駆動**：全イベントにおいてAIが事前にデータを準備し、「意見ではなくデータで始める」文化を確立する\[^10\]\[^8\]  
4. **アウトカム志向**：AIが生産量を爆発的に増やす環境では、「どれだけ作ったか」ではなく「どれだけ価値を届けたか」を全イベントの評価軸とする\[^1\]  
5. **エージェント・ガバナンス**：AIエージェントの動作品質を検査・改善する仕組みを正式なイベントとして組み込む（エージェント・キャリブレーション）\[^8\]

Scrum Guide Expansion Pack（2026年1月版）が警告するように、「AIは強みも弱みも増幅する。スクラムの実践が健全であればAIはその有効性を増幅するが、方向性や品質規律を欠いていればAIは機能不全を増幅する」。AI-DLCの成功は、ツールの導入ではなく、これらの原則に基づいてスクラムイベントを再設計し、「人間がAIを正しく導く」仕組みを制度化できるかにかかっています。\[^1\]

---

## References

1. [January 2026 (latest) | AI and Scrum \- Scrum Guide Expansion Pack](https://scrumexpansion.org/ai-and-scrum/2026.1/) \- AI can accelerate delivery, but it can also scale waste if you build the wrong things faster. This g...  
     
2. [Scrum Guide Expansion Pack (2025): Key Insights You ...](https://sensiolabs.com/blog/2025/scrum-guide-expansion-pack-2025-key-insights-you-need-to-know) \- A new building block has been added to the Scrum Guide to enrich it\! Does it offer real value, or is...  
     
3. [Moving from Weekly to Daily Sprints Using AI-Driven Productivity ...](https://www.linkedin.com/pulse/moving-from-weekly-daily-sprints-using-ai-driven-gains-brian-will-nekbe) \- With development work taking less time, it is conceivable to compress an agile sprint from the typic...  
     
4. [AI-Powered Dev Workflows | Redefining Agile & SDLC \- LinkedIn](https://www.linkedin.com/pulse/ai-powered-dev-workflows-from-weeks-hours-redefining-agile-brian-will-edmuf) \- Disclaimer: I am an employee of GitLab. The views and opinions expressed in this post are my own and...  
     
5. [From two weeks to two day Sprints: Rethinking Agile for the AI era](https://www.linkedin.com/pulse/from-two-weeks-day-sprints-rethinking-agile-ai-era-joteep-mahato-rlssc) \- For nearly last two decades Agile Scrum gave us discipline in a world where SDLC of coding, testing,...  
     
6. [From Two-Week Sprints to Daily Iterations with AI Agentic ...](https://www.osaas.io/blog/ai-agentic-development-daily-iterations) \- AI agentic development tools are reshaping how we build software. Combined with OSC hosted applicati...  
     
7. [How agentic AI is transforming software delivery lifecycles](https://blogs.opentext.com/agentic-ai-transforming-software-delivery-opentext/) \- Agentic AI can analyze backlogs, historical delivery data, and business objectives to recommend opti...  
     
8. [How AI Is Transforming Agile Software Delivery: AI in SDLC \- Ideas2IT](https://www.ideas2it.com/blogs/agentic-ai-agile-software-delivery) \- Discover how Agentic AI transforms Agile SDLC—boosting planning, QA, CI/CD, and retrospectives with ...  
     
9. [How AI Empowers Scrum Masters to Accelerate Team Flow](https://scaledagile.com/blog/ai-empowers-scrum-masters/) \- Discover how AI Scrum Masters are transforming agile. Learn about AI tools, benefits, and training. ...  
     
10. [How AI Transformed Daily Standups and Retrospectives](https://www.linkedin.com/posts/rodclaar_scrummaster-dailystandup-agileretrospective-activity-7395158859771850752-hQt3) \- ⏰ Daily Standups: From Time-Wasting Ritual to Data-Driven Powerhouse Most daily standups are broken....  
      
11. [Async Daily Standups for Software Teams: Implementation Case Study](https://aiadvisoryboard.me/blog/how-i-replaced-daily-standups-with-async-updates-a-team-lead?lang=en) \- Learn how a tech team lead successfully transitioned from traditional daily standups to async report...
