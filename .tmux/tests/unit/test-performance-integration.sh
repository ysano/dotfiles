#!/bin/bash
# Performance Integration Test
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–çµ±åˆãƒ†ã‚¹ãƒˆ

set -euo pipefail

# ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
TEST_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CLAUDE_HOME="$(dirname "$(dirname "$TEST_DIR")")"

# ã‚«ãƒ©ãƒ¼å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
source "$CLAUDE_HOME/claude/core/cache_manager.sh"
source "$CLAUDE_HOME/claude/core/performance_monitor.sh"
source "$CLAUDE_HOME/claude/services/detection_service.sh"

# === Test Functions ===

# ãƒ†ã‚¹ãƒˆçµ±è¨ˆ
declare -A TEST_RESULTS=(
    ["total"]=0
    ["passed"]=0
    ["failed"]=0
)

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°
run_test() {
    local test_name="$1"
    local test_function="$2"
    
    echo -e "${BLUE}Testing: $test_name${NC}"
    
    TEST_RESULTS["total"]=$((TEST_RESULTS["total"] + 1))
    
    if $test_function; then
        echo -e "${GREEN}âœ… PASS${NC} $test_name"
        TEST_RESULTS["passed"]=$((TEST_RESULTS["passed"] + 1))
        return 0
    else
        echo -e "${RED}âŒ FAIL${NC} $test_name"
        TEST_RESULTS["failed"]=$((TEST_RESULTS["failed"] + 1))
        return 1
    fi
}

# === Individual Test Cases ===

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åŸºæœ¬ãƒ†ã‚¹ãƒˆ
test_cache_manager_basic() {
    # åŸºæœ¬æ“ä½œ
    cache_set "test1" "value1" "10" || return 1
    
    local result=$(cache_get "test1")
    [[ "$result" == "value1" ]] || return 1
    
    cache_exists "test1" || return 1
    
    # TTL ãƒ†ã‚¹ãƒˆ
    cache_set "test_ttl" "short_lived" "1" || return 1
    sleep 2
    ! cache_exists "test_ttl" || return 1
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cache_delete "test1"
    return 0
}

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆç°¡ç•¥ç‰ˆï¼‰
test_cache_performance() {
    local iterations=10  # è² è·è»½æ¸›
    local start_time end_time duration
    
    # åŸºæœ¬çš„ãªèª­ã¿æ›¸ããƒ†ã‚¹ãƒˆ
    cache_set "perf_test_1" "test_value_1" "60" >/dev/null || return 1
    cache_set "perf_test_2" "test_value_2" "60" >/dev/null || return 1
    cache_set "perf_test_3" "test_value_3" "60" >/dev/null || return 1
    
    # èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    local result1=$(cache_get "perf_test_1" 2>/dev/null)
    local result2=$(cache_get "perf_test_2" 2>/dev/null)  
    local result3=$(cache_get "perf_test_3" 2>/dev/null)
    
    # çµæœæ¤œè¨¼
    [[ "$result1" == "test_value_1" ]] || return 1
    [[ "$result2" == "test_value_2" ]] || return 1
    [[ "$result3" == "test_value_3" ]] || return 1
    
    echo "  Cache read/write operations: âœ… Working"
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cache_delete "perf_test_1"
    cache_delete "perf_test_2"
    cache_delete "perf_test_3"
    return 0
}

# æ¤œå‡ºã‚µãƒ¼ãƒ“ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ
test_detection_service_integration() {
    # è¨­å®šæ›´æ–°ãƒ†ã‚¹ãƒˆ
    configure_detection_service "cache_ttl" "10" >/dev/null || return 1
    configure_detection_service "retry_count" "2" >/dev/null || return 1
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    clear_detection_cache >/dev/null || return 1
    
    # æ¤œå‡ºå®Ÿè¡Œãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ç’°å¢ƒï¼‰
    export MOCK_TERMINAL_OUTPUT="âœ» Thinkingâ€¦ (5s Â· 100 tokens Â· esc to interrupt)"
    source "$CLAUDE_HOME/claude/core/interfaces.sh"
    setup_test_mocks
    
    local result=$(detect_status_with_cache "test" "test" "false")
    [[ -n "$result" ]] || return 1
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
    local cached_result=$(detect_status_with_cache "test" "test" "true")
    [[ "$cached_result" == "$result" ]] || return 1
    
    cleanup_test_mocks
    return 0
}

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ†ã‚¹ãƒˆ
test_performance_monitoring() {
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ†ã‚¹ãƒˆ
    collect_system_metrics || return 1
    
    # å¿œç­”æ™‚é–“æ¸¬å®šãƒ†ã‚¹ãƒˆ
    measure_claude_detection_performance || return 1
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    local cpu_percent="${PERFORMANCE_METRICS[cpu_percent]}"
    local memory_percent="${PERFORMANCE_METRICS[memory_percent]}"
    local response_time="${PERFORMANCE_METRICS[response_time_ms]}"
    
    # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    [[ $cpu_percent -ge 0 && $cpu_percent -le 100 ]] || return 1
    [[ $memory_percent -ge 0 && $memory_percent -le 100 ]] || return 1
    [[ $response_time -ge 0 ]] || return 1
    
    return 0
}

# è¨­å®šç®¡ç†çµ±åˆãƒ†ã‚¹ãƒˆ
test_config_integration() {
    source "$CLAUDE_HOME/claude/core/config_manager_v2.sh"
    
    # åŸºæœ¬è¨­å®šãƒ†ã‚¹ãƒˆ
    local version=$(get_config "system.version" "unknown")
    [[ "$version" != "unknown" ]] || return 1
    
    # ç’°å¢ƒæ¤œå‡ºãƒ†ã‚¹ãƒˆ
    local env=$(detect_environment)
    [[ -n "$env" ]] || return 1
    
    # è¨­å®šå¤‰æ›´ãƒ†ã‚¹ãƒˆ
    local old_ttl=$(get_config "performance.cache_ttl")
    set_config "performance.cache_ttl" "15" "false" "system" >/dev/null || return 1
    local new_ttl=$(get_config "performance.cache_ttl")
    [[ "$new_ttl" == "15" ]] || return 1
    
    # å…ƒã«æˆ»ã™
    set_config "performance.cache_ttl" "$old_ttl" "false" "system" >/dev/null
    
    return 0
}

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
test_architecture_consistency() {
    source "$CLAUDE_HOME/claude/core/module_registry_v2.sh"
    
    # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¤œè¨¼
    validate_dependency_direction >/dev/null || return 1
    detect_circular_dependencies >/dev/null || return 1
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿é †åºãƒ†ã‚¹ãƒˆ
    local test_modules=("detection_service" "cache_manager")
    local load_order=($(calculate_load_order "${test_modules[@]}"))
    [[ ${#load_order[@]} -ge 2 ]] || return 1
    
    return 0
}

# ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
test_end_to_end_performance() {
    # ãƒªã‚¢ãƒ«ãªãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    local iterations=50
    local total_time=0
    local successful_detections=0
    
    # ãƒ¢ãƒƒã‚¯ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    export MOCK_TERMINAL_OUTPUT="âœ» Processingâ€¦ (3s Â· 50 tokens Â· esc to interrupt)"
    setup_test_mocks
    
    for ((i=1; i<=iterations; i++)); do
        local start_time=$(date +%s%N)
        
        # æ¤œå‡ºå®Ÿè¡Œ
        if detect_current_pane >/dev/null 2>&1; then
            ((successful_detections++))
        fi
        
        local end_time=$(date +%s%N)
        local duration=$(( (end_time - start_time) / 1000000 ))
        total_time=$((total_time + duration))
        
        # çŸ­æ™‚é–“å¾…æ©Ÿã§ãƒªã‚¢ãƒ«ãªãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        sleep 0.1
    done
    
    cleanup_test_mocks
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ãƒã‚§ãƒƒã‚¯
    local avg_time=$((total_time / iterations))
    local success_rate=$(( (successful_detections * 100) / iterations ))
    
    # å¹³å‡50msä»¥å†…ã€æˆåŠŸç‡80%ä»¥ä¸Š
    [[ $avg_time -lt 50 ]] || return 1
    [[ $success_rate -gt 80 ]] || return 1
    
    echo "  Performance: ${avg_time}ms avg, ${success_rate}% success rate"
    return 0
}

# === Main Test Execution ===

main() {
    echo -e "${BLUE}ğŸš€ Performance Integration Test Suite${NC}"
    echo -e "${BLUE}===================================${NC}"
    echo ""
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    run_test "Cache Manager Basic Operations" test_cache_manager_basic
    echo ""
    
    run_test "Cache Performance Benchmarks" test_cache_performance
    echo ""
    
    run_test "Detection Service Integration" test_detection_service_integration
    echo ""
    
    run_test "Performance Monitoring" test_performance_monitoring
    echo ""
    
    run_test "Configuration Management Integration" test_config_integration
    echo ""
    
    run_test "Architecture Consistency" test_architecture_consistency
    echo ""
    
    run_test "End-to-End Performance" test_end_to_end_performance
    echo ""
    
    # çµæœã‚µãƒãƒªãƒ¼
    echo -e "${YELLOW}=== Test Results ===${NC}"
    echo "Total tests: ${TEST_RESULTS[total]}"
    echo -e "Passed: ${GREEN}${TEST_RESULTS[passed]}${NC}"
    echo -e "Failed: ${RED}${TEST_RESULTS[failed]}${NC}"
    
    local success_rate=0
    if [[ ${TEST_RESULTS[total]} -gt 0 ]]; then
        success_rate=$(( (TEST_RESULTS[passed] * 100) / TEST_RESULTS[total] ))
    fi
    echo "Success rate: ${success_rate}%"
    
    if [[ ${TEST_RESULTS[failed]} -eq 0 ]]; then
        echo -e "${GREEN}ğŸ‰ All performance integration tests passed!${NC}"
        return 0
    else
        echo -e "${RED}ğŸ’¥ Some tests failed!${NC}"
        return 1
    fi
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"