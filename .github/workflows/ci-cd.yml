name: Claude Voice Integration CI/CD v2

on:
  push:
    branches: [ master, develop, refactor/* ]
    paths:
      - '.tmux/claude/**'
      - '.tmux/tests/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ master ]
    paths:
      - '.tmux/claude/**'
      - '.tmux/tests/**'

env:
  CLAUDE_VOICE_HOME: ${{ github.workspace }}/.tmux/claude
  CI: true
  FORCE_COLOR: 1

# Job concurrency control
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Pre-flight checks - very fast validation
  pre-flight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should-run-tests: ${{ steps.changes.outputs.tests }}
      should-run-security: ${{ steps.changes.outputs.security }}
      matrix-tests: ${{ steps.setup.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changes
        id: changes
        run: |
          # Check what types of changes were made
          if git diff --name-only HEAD^ | grep -q "\.tmux/claude/.*\.sh$"; then
            echo "tests=true" >> $GITHUB_OUTPUT
          else
            echo "tests=false" >> $GITHUB_OUTPUT
          fi
          
          if git diff --name-only HEAD^ | grep -qE "(security|auth|powershell|windows)"; then
            echo "security=true" >> $GITHUB_OUTPUT
          else
            echo "security=false" >> $GITHUB_OUTPUT
          fi

      - name: Setup test matrix
        id: setup
        run: |
          # Dynamically create test matrix based on available modules
          modules=$(find .tmux/claude/core -name "*.sh" -type f -exec basename {} .sh \; | sort)
          echo "matrix=$(echo "$modules" | jq -R -s -c 'split("\n")[:-1]')" >> $GITHUB_OUTPUT

      - name: Validate basic structure
        run: |
          # Quick structural validation
          required_dirs=(".tmux/claude/core" ".tmux/claude/tests")
          for dir in "${required_dirs[@]}"; do
            if [[ ! -d "$dir" ]]; then
              echo "‚ùå Required directory missing: $dir"
              exit 1
            fi
          done
          echo "‚úÖ Basic structure validation passed"

  # Enhanced linting with caching
  lint-and-format:
    name: Lint & Format
    runs-on: ubuntu-latest
    needs: pre-flight
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache linting tools
        uses: actions/cache@v4
        with:
          path: |
            ~/.local/bin/shellcheck
            ~/.local/bin/shfmt
          key: linting-tools-${{ runner.os }}-v1

      - name: Install linting tools
        run: |
          # Install shellcheck
          if ! command -v shellcheck >/dev/null 2>&1; then
            wget -qO- "https://github.com/koalaman/shellcheck/releases/download/v0.9.0/shellcheck-v0.9.0.linux.x86_64.tar.xz" | tar -xJv
            cp "shellcheck-v0.9.0/shellcheck" ~/.local/bin/
            chmod +x ~/.local/bin/shellcheck
          fi
          
          # Install shfmt
          if ! command -v shfmt >/dev/null 2>&1; then
            curl -L "https://github.com/mvdan/sh/releases/download/v3.7.0/shfmt_v3.7.0_linux_amd64" -o ~/.local/bin/shfmt
            chmod +x ~/.local/bin/shfmt
          fi
          
          # Install yamllint
          pip install --user yamllint

      - name: Enhanced ShellCheck
        run: |
          echo "üîç Running enhanced ShellCheck analysis..."
          
          # Create detailed shellcheck configuration
          cat > .shellcheckrc << 'EOF'
          exclude=SC1090,SC1091,SC2034,SC2086
          external-sources=true
          check-sourced=true
          EOF
          
          # Run shellcheck with detailed reporting
          find .tmux/claude -name "*.sh" -type f | while read -r script; do
            echo "Checking $script..."
            ~/.local/bin/shellcheck --format=gcc "$script" || exit 1
          done
          
          echo "‚úÖ All shell scripts pass enhanced ShellCheck"

      - name: Format validation
        run: |
          echo "üìù Validating shell script formatting..."
          
          format_issues=0
          find .tmux/claude -name "*.sh" -type f | while read -r script; do
            if ! ~/.local/bin/shfmt -d -i 4 -ci "$script"; then
              echo "‚ùå Format issues in $script"
              format_issues=$((format_issues + 1))
            fi
          done
          
          if [[ $format_issues -gt 0 ]]; then
            echo "‚ùå Found $format_issues files with formatting issues"
            exit 1
          fi
          
          echo "‚úÖ All scripts properly formatted"

      - name: YAML and configuration validation
        run: |
          echo "üìã Validating configuration files..."
          
          # YAML validation
          find .tmux/claude -name "*.yml" -o -name "*.yaml" 2>/dev/null | while read -r yaml_file; do
            echo "Validating $yaml_file..."
            python3 -c "import yaml; yaml.safe_load(open('$yaml_file'))" || exit 1
            yamllint -d relaxed "$yaml_file" || exit 1
          done
          
          echo "‚úÖ Configuration validation passed"

  # Comprehensive testing with parallel execution
  test-suite:
    name: Test Suite (${{ matrix.test-type }})
    runs-on: ubuntu-latest
    needs: [pre-flight, lint-and-format]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        test-type: [unit, integration, security, performance]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache test dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/test-deps
            /tmp/claude-test-cache
          key: test-deps-${{ runner.os }}-${{ hashFiles('.tmux/claude/tests/**') }}

      - name: Setup enhanced test environment
        run: |
          # Create comprehensive test environment
          mkdir -p $CLAUDE_VOICE_HOME/{logs,tests/output,cache}
          mkdir -p ~/.cache/test-deps
          
          # Install enhanced dependencies
          sudo apt-get update
          sudo apt-get install -y jq curl bc parallel time stress-ng
          
          # Setup test isolation
          export CLAUDE_VOICE_TEST_MODE=true
          export CLAUDE_VOICE_TEST_ISOLATION=true
          
          # Create mock services for testing
          cat > /tmp/mock-services.sh << 'EOF'
          #!/bin/bash
          # Mock external services for testing
          
          mock_ollama() {
            case "$1" in
              "list") echo '{"models": [{"name": "phi4-mini:latest", "size": 1000000}]}';;
              "ps") echo '{"models": []}';;
              "pull") echo "‚úÖ Mock pull: $2"; sleep 0.1;;
              *) echo "Mock Ollama: $*";;
            esac
          }
          
          mock_powershell() {
            case "$*" in
              *"Get-ExecutionPolicy"*) echo "RemoteSigned";;
              *"System.Speech"*) echo "Speech synthesis mock";;
              *) echo "Mock PowerShell output";;
            esac
          }
          
          # Export functions
          export -f mock_ollama mock_powershell
          EOF
          
          source /tmp/mock-services.sh

      - name: Module dependency validation
        run: |
          echo "üîó Validating module dependencies..."
          
          cd .tmux/claude/core
          
          # Check each module can be sourced independently
          for module in *.sh; do
            if [[ -f "$module" ]]; then
              echo "Testing $module..."
              bash -n "$module" || {
                echo "‚ùå Syntax error in $module"
                exit 1
              }
            fi
          done
          
          echo "‚úÖ All modules have valid syntax"

      - name: Run ${{ matrix.test-type }} tests
        run: |
          cd .tmux/claude/tests
          
          # Enhanced test execution with detailed reporting
          case "${{ matrix.test-type }}" in
            "unit")
              echo "üß™ Running unit tests..."
              chmod +x test_runner.sh
              
              # Run with enhanced monitoring
              timeout 600 ./test_runner.sh unit 2>&1 | tee unit-test-output.log
              
              # Generate coverage report
              echo "üìä Generating test coverage report..."
              covered_functions=$(grep -o "Testing function: [a-zA-Z_]*" unit-test-output.log | wc -l)
              total_functions=$(find ../core -name "*.sh" -exec grep -c "^[a-zA-Z_]*() {" {} + | awk '{sum+=$1} END {print sum}')
              coverage=$((covered_functions * 100 / total_functions))
              echo "Test coverage: $coverage% ($covered_functions/$total_functions functions)"
              ;;
              
            "integration")
              echo "üîó Running integration tests..."
              timeout 600 ./test_runner.sh integration 2>&1 | tee integration-test-output.log
              ;;
              
            "security")
              echo "üîí Running security tests..."
              timeout 300 ./test_runner.sh security 2>&1 | tee security-test-output.log
              ;;
              
            "performance")
              echo "‚ö° Running performance tests..."
              
              # Performance baseline testing
              start_time=$(date +%s%3N)
              timeout 300 ./test_runner.sh performance 2>&1 | tee performance-test-output.log
              end_time=$(date +%s%3N)
              
              duration=$((end_time - start_time))
              echo "Performance test duration: ${duration}ms"
              
              # Fail if performance tests take too long
              if [[ $duration -gt 30000 ]]; then
                echo "‚ùå Performance tests exceeded 30s threshold"
                exit 1
              fi
              ;;
          esac

      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-type }}-${{ github.sha }}
          path: |
            .tmux/claude/tests/*-output.log
            .tmux/claude/tests/output/
            .tmux/claude/logs/
          retention-days: 14

  # Enhanced security scanning
  security-scan:
    name: Security Analysis
    runs-on: ubuntu-latest
    needs: pre-flight
    if: needs.pre-flight.outputs.should-run-security == 'true'
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Advanced secret scanning
        run: |
          echo "üîç Running advanced secret detection..."
          
          # Multi-pattern secret detection
          secret_patterns=(
            "password['\"]?\s*[:=]\s*['\"][^'\"]*['\"]"
            "api[_-]?key['\"]?\s*[:=]\s*['\"][^'\"]*['\"]"
            "secret['\"]?\s*[:=]\s*['\"][^'\"]*['\"]"
            "token['\"]?\s*[:=]\s*['\"][^'\"]*['\"]"
            "[A-Za-z0-9]{32,}"
          )
          
          secrets_found=0
          for pattern in "${secret_patterns[@]}"; do
            if grep -r -E "$pattern" .tmux/claude/ --include="*.sh" --include="*.conf" | grep -v -E "(example|test|mock|dummy)"; then
              echo "‚ùå Potential secret found with pattern: $pattern"
              secrets_found=1
            fi
          done
          
          if [[ $secrets_found -eq 1 ]]; then
            echo "‚ùå Security scan failed - potential secrets detected"
            exit 1
          fi
          
          echo "‚úÖ No secrets detected"

      - name: Vulnerability pattern analysis
        run: |
          echo "üõ°Ô∏è Analyzing vulnerability patterns..."
          
          vuln_found=0
          
          # Command injection patterns
          if grep -r -E '\$\([^)]*\$[^)]*\)' .tmux/claude/ --include="*.sh" | grep -v "# Safe:"; then
            echo "‚ö†Ô∏è Potential command injection pattern detected"
            vuln_found=1
          fi
          
          # Path traversal patterns
          if grep -r -E '\.\./|\.\.\\' .tmux/claude/ --include="*.sh" | grep -v "# Safe:"; then
            echo "‚ö†Ô∏è Potential path traversal pattern detected"
            vuln_found=1
          fi
          
          # Unsafe eval patterns
          if grep -r -E '\beval\s+' .tmux/claude/ --include="*.sh" | grep -v "# Safe:"; then
            echo "‚ùå Unsafe eval usage detected"
            vuln_found=1
          fi
          
          if [[ $vuln_found -eq 1 ]]; then
            echo "‚ùå Vulnerability analysis failed"
            exit 1
          fi
          
          echo "‚úÖ Vulnerability analysis passed"

      - name: File permission audit
        run: |
          echo "üîê Auditing file permissions..."
          
          # Check for overly permissive files
          perm_issues=0
          
          find .tmux/claude -type f \( -perm /o+w -o -perm /g+w \) | while read -r file; do
            echo "‚ùå Overly permissive file: $file"
            perm_issues=1
          done
          
          # Check for missing execute permissions on scripts
          find .tmux/claude -name "*.sh" -type f ! -executable | while read -r script; do
            echo "‚ö†Ô∏è Script missing execute permission: $script"
          done
          
          echo "‚úÖ File permission audit completed"

  # Performance and resource monitoring
  performance-analysis:
    name: Performance Analysis
    runs-on: ubuntu-latest
    needs: [lint-and-format]
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Module load performance
        run: |
          echo "‚ö° Analyzing module load performance..."
          
          cd .tmux/claude/core
          
          total_load_time=0
          module_count=0
          
          for module in *.sh; do
            if [[ -f "$module" ]]; then
              echo "Testing load time for $module..."
              
              start_time=$(date +%s%3N)
              bash -n "$module"
              end_time=$(date +%s%3N)
              
              load_time=$((end_time - start_time))
              total_load_time=$((total_load_time + load_time))
              module_count=$((module_count + 1))
              
              echo "$module: ${load_time}ms"
              
              # Warn if individual module is slow
              if [[ $load_time -gt 500 ]]; then
                echo "‚ö†Ô∏è $module load time exceeds 500ms"
              fi
            fi
          done
          
          avg_load_time=$((total_load_time / module_count))
          echo "Average module load time: ${avg_load_time}ms"
          echo "Total estimated load time: ${total_load_time}ms"
          
          # Performance thresholds
          if [[ $total_load_time -gt 5000 ]]; then
            echo "‚ùå Total module load time exceeds 5s threshold"
            exit 1
          fi

      - name: Memory usage analysis
        run: |
          echo "üíæ Analyzing memory usage patterns..."
          
          # Simulate memory usage during module loading
          cd .tmux/claude/core
          
          # Monitor memory during source operations
          memory_before=$(free -m | awk 'NR==2{print $3}')
          
          # Source all modules in test environment
          for module in *.sh; do
            if [[ -f "$module" ]]; then
              bash -c "source $module" 2>/dev/null || true
            fi
          done
          
          memory_after=$(free -m | awk 'NR==2{print $3}')
          memory_diff=$((memory_after - memory_before))
          
          echo "Memory usage delta: ${memory_diff}MB"
          
          # Reasonable memory usage threshold
          if [[ $memory_diff -gt 100 ]]; then
            echo "‚ö†Ô∏è High memory usage detected: ${memory_diff}MB"
          fi

  # Code quality metrics
  quality-metrics:
    name: Quality Metrics
    runs-on: ubuntu-latest
    needs: [lint-and-format]
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Collect comprehensive metrics
        run: |
          echo "üìä Collecting code quality metrics..."
          
          # Initialize metrics
          total_lines=0
          total_functions=0
          total_files=0
          complex_functions=0
          documented_functions=0
          
          # Create detailed metrics report
          cat > quality-report.md << 'EOF'
          # Code Quality Report
          
          ## Overview
          EOF
          
          echo "| Module | Lines | Functions | Avg Function Length | Documentation |" >> quality-report.md
          echo "|--------|-------|-----------|-------------------|---------------|" >> quality-report.md
          
          find .tmux/claude/core -name "*.sh" -type f | sort | while read -r script; do
            module_name=$(basename "$script" .sh)
            lines=$(wc -l < "$script")
            functions=$(grep -c "^[a-zA-Z_][a-zA-Z0-9_]*() *{" "$script" 2>/dev/null || echo 0)
            
            # Calculate average function length
            if [[ $functions -gt 0 ]]; then
              avg_func_length=$((lines / functions))
            else
              avg_func_length=0
            fi
            
            # Check documentation coverage
            documented=$(grep -B5 "^[a-zA-Z_][a-zA-Z0-9_]*() *{" "$script" | grep -c "^#" || echo 0)
            doc_percentage=0
            if [[ $functions -gt 0 ]]; then
              doc_percentage=$((documented * 100 / functions))
            fi
            
            echo "| $module_name | $lines | $functions | $avg_func_length | $doc_percentage% |" >> quality-report.md
            
            # Update totals
            total_lines=$((total_lines + lines))
            total_functions=$((total_functions + functions))
            total_files=$((total_files + 1))
            
            # Check for complex functions
            if [[ $avg_func_length -gt 50 ]]; then
              complex_functions=$((complex_functions + 1))
            fi
            
            if [[ $doc_percentage -gt 50 ]]; then
              documented_functions=$((documented_functions + 1))
            fi
          done
          
          # Add summary
          cat >> quality-report.md << EOF
          
          ## Summary
          - **Total Files**: $total_files
          - **Total Lines**: $total_lines
          - **Total Functions**: $total_functions
          - **Average Lines per File**: $((total_lines / total_files))
          - **Average Functions per File**: $((total_functions / total_files))
          - **Complex Functions**: $complex_functions
          - **Well-documented Modules**: $documented_functions/$total_files
          
          ## Quality Scores
          - **Maintainability**: $(( (total_files * 100) / (complex_functions + 1) ))%
          - **Documentation Coverage**: $(( documented_functions * 100 / total_files ))%
          EOF
          
          echo "Quality metrics collected:"
          cat quality-report.md

      - name: Upload quality report
        uses: actions/upload-artifact@v4
        with:
          name: quality-metrics-${{ github.sha }}
          path: quality-report.md
          retention-days: 30

  # Deployment readiness check
  deployment-readiness:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    needs: [test-suite, security-scan, performance-analysis, quality-metrics]
    if: github.ref == 'refs/heads/master'
    timeout-minutes: 10
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Readiness validation
        run: |
          echo "üöÄ Validating deployment readiness..."
          
          readiness_score=0
          max_score=100
          
          # Test results check (30 points)
          if [[ "${{ needs.test-suite.result }}" == "success" ]]; then
            readiness_score=$((readiness_score + 30))
            echo "‚úÖ Tests passed (+30 points)"
          else
            echo "‚ùå Tests failed (0 points)"
          fi
          
          # Security check (25 points)
          if [[ "${{ needs.security-scan.result }}" == "success" ]]; then
            readiness_score=$((readiness_score + 25))
            echo "‚úÖ Security scan passed (+25 points)"
          else
            echo "‚ùå Security scan failed (0 points)"
          fi
          
          # Performance check (25 points)
          if [[ "${{ needs.performance-analysis.result }}" == "success" ]]; then
            readiness_score=$((readiness_score + 25))
            echo "‚úÖ Performance analysis passed (+25 points)"
          else
            echo "‚ùå Performance analysis failed (0 points)"
          fi
          
          # Quality metrics (20 points)
          if [[ "${{ needs.quality-metrics.result }}" == "success" ]]; then
            readiness_score=$((readiness_score + 20))
            echo "‚úÖ Quality metrics collected (+20 points)"
          else
            echo "‚ùå Quality metrics failed (0 points)"
          fi
          
          echo "Deployment readiness score: $readiness_score/$max_score"
          
          # Deployment threshold
          if [[ $readiness_score -ge 80 ]]; then
            echo "üéâ Deployment ready! Score: $readiness_score%"
            echo "deployment-ready=true" >> $GITHUB_OUTPUT
          else
            echo "üö´ Deployment not ready. Score: $readiness_score% (minimum: 80%)"
            echo "deployment-ready=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Create deployment package
        if: steps.readiness.outputs.deployment-ready == 'true'
        run: |
          echo "üì¶ Creating optimized deployment package..."
          
          # Create versioned package
          version=$(date +%Y%m%d-%H%M%S)
          package_name="claude-voice-v$version"
          
          mkdir -p "dist/$package_name"
          
          # Copy optimized files
          cp -r .tmux/claude/core "dist/$package_name/"
          cp -r .tmux/claude/tests "dist/$package_name/"
          
          # Create optimized install script
          cat > "dist/$package_name/install.sh" << 'EOF'
          #!/bin/bash
          set -euo pipefail
          
          INSTALL_DIR="${HOME}/.tmux/claude"
          VERSION="v$version"
          
          echo "üöÄ Installing Claude Voice Integration $VERSION..."
          
          # Backup existing installation
          if [[ -d "$INSTALL_DIR" ]]; then
            backup_dir="${INSTALL_DIR}.backup.$(date +%s)"
            echo "üìã Backing up existing installation to $backup_dir"
            mv "$INSTALL_DIR" "$backup_dir"
          fi
          
          # Create directories
          mkdir -p "$INSTALL_DIR"/{core,logs,tests,cache}
          
          # Copy files with verification
          echo "üìÅ Installing core modules..."
          cp -r core/* "$INSTALL_DIR/core/"
          
          echo "üß™ Installing test suite..."
          cp -r tests/* "$INSTALL_DIR/tests/"
          
          # Set optimal permissions
          find "$INSTALL_DIR" -name "*.sh" -exec chmod +x {} \;
          
          # Run post-install validation
          echo "‚úÖ Running post-install validation..."
          cd "$INSTALL_DIR/tests"
          ./test_runner.sh unit --quick || {
            echo "‚ùå Post-install validation failed"
            exit 1
          }
          
          echo "üéâ Claude Voice Integration $VERSION installed successfully!"
          echo "üìç Installation location: $INSTALL_DIR"
          echo "üîß Run full tests: cd $INSTALL_DIR/tests && ./test_runner.sh"
          EOF
          
          chmod +x "dist/$package_name/install.sh"
          
          # Create archive with compression
          cd dist
          tar -czf "$package_name.tar.gz" "$package_name/"
          
          echo "Package created: $package_name.tar.gz"
          ls -lh "$package_name.tar.gz"

      - name: Upload deployment package
        uses: actions/upload-artifact@v4
        with:
          name: deployment-package-${{ github.sha }}
          path: dist/
          retention-days: 90

  # Comprehensive reporting
  final-report:
    name: CI/CD Report
    runs-on: ubuntu-latest
    needs: [pre-flight, lint-and-format, test-suite, security-scan, performance-analysis, quality-metrics, deployment-readiness]
    if: always()
    steps:
      - name: Generate comprehensive report
        run: |
          echo "üìä Generating CI/CD report..."
          
          cat > ci-report.md << 'EOF'
          # Claude Voice Integration CI/CD Report
          
          ## Pipeline Summary
          EOF
          
          # Calculate overall success rate
          total_jobs=7
          successful_jobs=0
          
          jobs=(
            "lint-and-format:${{ needs.lint-and-format.result }}"
            "test-suite:${{ needs.test-suite.result }}"
            "security-scan:${{ needs.security-scan.result }}"
            "performance-analysis:${{ needs.performance-analysis.result }}"
            "quality-metrics:${{ needs.quality-metrics.result }}"
            "deployment-readiness:${{ needs.deployment-readiness.result }}"
          )
          
          echo "| Job | Status | Duration |" >> ci-report.md
          echo "|-----|--------|----------|" >> ci-report.md
          
          for job_result in "${jobs[@]}"; do
            job_name=$(echo "$job_result" | cut -d: -f1)
            job_status=$(echo "$job_result" | cut -d: -f2)
            
            if [[ "$job_status" == "success" ]]; then
              status_icon="‚úÖ"
              successful_jobs=$((successful_jobs + 1))
            elif [[ "$job_status" == "skipped" ]]; then
              status_icon="‚è≠Ô∏è"
            else
              status_icon="‚ùå"
            fi
            
            echo "| $job_name | $status_icon $job_status | - |" >> ci-report.md
          done
          
          success_rate=$((successful_jobs * 100 / total_jobs))
          
          cat >> ci-report.md << EOF
          
          ## Overall Results
          - **Success Rate**: $success_rate% ($successful_jobs/$total_jobs jobs)
          - **Commit**: ${{ github.sha }}
          - **Branch**: ${{ github.ref_name }}
          - **Triggered by**: ${{ github.event_name }}
          
          ## Next Steps
          EOF
          
          if [[ $success_rate -ge 85 ]]; then
            echo "üéâ **Pipeline Status**: PASSED" >> ci-report.md
            echo "- All critical checks completed successfully" >> ci-report.md
            echo "- Ready for deployment/merge" >> ci-report.md
          else
            echo "üö´ **Pipeline Status**: FAILED" >> ci-report.md
            echo "- Review failed jobs and address issues" >> ci-report.md
            echo "- Re-run pipeline after fixes" >> ci-report.md
          fi
          
          echo "CI/CD Report generated:"
          cat ci-report.md

      - name: Update GitHub summary
        run: |
          # Add report to GitHub step summary
          cat ci-report.md >> $GITHUB_STEP_SUMMARY
