# AI-DLC Role Transformation

AI-DLC（AI-Driven Development Lifecycle）における4つのマネジメント役割の変革ガイド。
従来の「作業管理者」から「AI-人間協働のオーケストレーター」への移行を Why / What / How の三層で解説する。

## Why: ボトルネックの移動

AI エージェントがコーディング・テスト・ドキュメント作成を高速処理する環境では、ボトルネックが移動する:

| 従来のボトルネック | AI-DLC のボトルネック |
|---|---|
| コードを書く力 | 何を作るべきかの判断力 |
| 技術的実現可能性 | AI 出力の検証力 |
| 開発工数の確保 | 価値仮説の設計と高速検証 |

AI の能力を引き出す鍵は技術ではなく、**人間の役割設計**にある。

---

## Product Owner → Value Orchestrator

### 最重要の変化

「バックログ優先順位管理者」から「AI エージェントへのコグニティブ・オーケストレーター（認知の指揮者）」へ。
AI-DLC において**唯一、重要度が上がる**役割。AI に明確なゴール・コンテキスト・制約を与え、その結果をユーザー価値のレンズで解釈する。

### 核心的な問い

AI は「ほぼ何でも作れる」ため、技術的実現可能性はボトルネックではない。PO が答えるべき問い:

1. **Desirability**: この機能は本当にユーザーの行動を変えるか？
2. **検証可能な仮説**: 仮説として定義できるか？
3. **検証ループ設計**: AI が高速で作った場合、どう検証するか？

### Outcome Done の設計

2層の Done 定義を管理する:

- **Output Done**（出力完了）: コードが動く、テストが通る、セキュリティスキャンがグリーン
- **Outcome Done**（成果完了）: この変更がユーザーの行動・体験・結果を改善した証拠は何か？

Output Done だけでは「高速フィーチャーファクトリー」を作るだけ。Outcome Done の基準がチームを価値創出に向かわせる。

### Atomic Spec 品質保証

Atomic Spec（背景・現状・あるべき姿・制約・検証方法）の5要素の品質は PO の責任。AI エージェントは曖昧な指示に対して推測で補完し、ハルシネーションの原因を作る。**スペックの明確さ＝AI の出力品質**。

### 高速仮説検証

AI が数時間で MVP を生成できるため「1スプリント=1仮説検証」が可能に:

- A/Bテスト、ベータリリース、ユーザーインタビューの頻度を劇的に上げる
- 「作ってから検証する」→「検証するために作る」へマインドセット転換
- 成果を出さなかった AI 生成機能を躊躇なく廃棄する決断力

---

## Scrum Master → Agent Orchestration Coach

### 最重要の変化

「人間同士のコミュニケーション最適化」から「人間-AI インタラクションシステム最適化」へ。
従来業務（ファシリテーション、障害除去、コーチング）の多くは AI で自動化可能。焦点が根本的に変わる。

### AI-人間ワーキングアグリーメント

SM の最重要業務は「AI エージェントとの新しいワーキングアグリーメントの策定」:

- **アカウンタビリティ原則**: AI は作業を生成できるが、人間がアカウンタビリティを持つ
- **行動範囲**: AI エージェントの allowedTools と停止条件の明文化
- **緊急停止メカニズム**: エージェントが予期しない結果を出した場合の対処手順

### Hooks・ガードレール運用

Hooks 設定（check-spec-existence、auto-update-ticket 等）の運用・改善は SM の責務。従来の「プロセス改善」が「コードとしてのガードレール改善」に進化した形。

- `settings-ai-dlc.json` プリセットの導入と調整
- PreToolUse / PostToolUse フックの追加・除去判断
- ガードレール効果のレトロスペクティブでの振り返り

### 新メトリクス

従来のベロシティ・バーンダウンに加え:

| メトリクス | 定義 | SM の責務 |
|---|---|---|
| **MTTV**（平均検証時間） | チケット作成からユーザー検証完了までの時間 | 追跡と改善 |
| **Interaction Churn** | AI エージェントとの手戻り回数 | 分析とスペック品質へのフィードバック |
| **AI-Confidence** | AI が出力に付与する確信度スコアの分布 | モニタリングと閾値調整 |

### 自動化バイアスの防止

人間は AI の提案を過信する傾向がある。「AI が提案し、人間が決定する」原則が形骸化していないかを常に監視し、チームの主体性を守る。

---

## Product Manager → AI Strategy Architect

### 最重要の変化

**Feature-First 思考から AI-Capability 思考へ**。

| 従来 | AI-DLC |
|---|---|
| ユーザーにはどんな機能が必要か？ | AI とドメイン知識でどんな新しい価値を生み出せるか？ |
| 離散的な機能を定義 | 複数の AI ケイパビリティの組み合わせを設計 |
| 仕様書を書いて開発チームに渡す | プロトタイプで即検証 |

PM は自ら Claude Code 等を使ってプロトタイプを数時間で作り、「説明する」のではなく「見せる」ことが可能に。

### 仮説探索空間の拡大

AI により**並列で数十の仮説を探索**できる:

- 複数の UI 案・コピー案・技術アプローチを同時にプロトタイプ化
- 「最も声の大きい人の案」ではなく「データで検証された案」を選択
- 従来数ヶ月の逐次的反復を並列で数日に圧縮

### 優先順位フレームワーク更新

AI は優先順位付けの4次元すべてを変える:

| 次元 | 従来 | AI-DLC |
|---|---|---|
| **Feasibility** | 技術的に複雑なものは低スコア | AI により従来不可能な解決策が実現可能に |
| **Impact** | 想定ベースの定性評価 | AI パーソナライゼーションで特定問題のインパクト増大 |
| **Risk** | 技術リスク中心 | ハルシネーション、バイアス、倫理リスクが追加 |
| **Cost** | 開発工数ベース | API 利用料・推論コストが新変数に |

### PO との分担

- **PM（AI Strategy Architect）**: 市場トレンド、顧客課題、ポジショニング、長期ビジョン、AI-Capability 戦略
- **PO（Value Orchestrator）**: 戦略をスプリント単位の検証可能な仮説に分解し、チーム＋AI エージェントと実行・検証

小規模チーム（ケンタウロス・ポッド）では兼務可、スクワッド以上では分離を推奨。

---

## Project Manager → Delivery System Operator

### 最重要の変化

「コーディネーター PM」と「判断 PM（Decision PM）」への**二極化**。AI がスケジュール管理・進捗報告・リスク追跡を自動化する結果、ステータス報告だけの PM はコモディティ化する。

### AI 予測の解釈

AI はプロジェクトリスクを削減し完了時間を短縮できるが、それは予測を**正しく解釈する**人間がいる場合に限る:

- リスクシグナルの**誤検知と真のリスクの識別**
- 複数の対応策から**組織コンテキストを考慮した最適解の選択**
- ステークホルダーへの**AI 分析結果の翻訳と説明責任**

### デリバリーパイプライン最適化

AI-DLC では「コードを書く」フェーズが圧縮され、レビュー・検証・デプロイがボトルネックに:

- **バリューストリーム全体**（アイデア→開発→リリース→学習）のフロー最適化
- ハンドオフ・待ち時間・承認プロセスの AI 活用による自動化推進
- 組織の階層的承認プロセスが「AI の速度に追いつけない」問題の解決

### スケール別の位置づけ

| スケール | PjM の位置づけ |
|---|---|
| **Pod（1-10名）** | 他役割（SM/PO）に吸収される傾向 |
| **Squad（10-30名）** | デリバリー調整として部分的に必要 |
| **Enterprise（30名以上）** | 複数チーム横断のガバナンス・ステークホルダーマネジメントとして専門性が必須 |

---

## 共通原則: 人間の判断に集中

4役割に共通する変化の本質は「AI が自動化できない人間固有の判断に集中する」こと。

| 人間にしかできないこと | AI が代替できること |
|---|---|
| 「なぜこれを作るべきか」の判断 | 「どう実装するか」の実行 |
| ステークホルダー間の利害調整・政治的判断 | データ分析・パターン認識 |
| 倫理的判断（バイアス、公平性） | スケジュール管理・進捗追跡 |
| チームの心理的安全性の構築 | ステータス報告・ミーティング要約 |
| 不確実性の中での意思決定 | リスクの定量的予測 |
| ユーザーの言語化されていないニーズの理解 | 既存フィードバックの分析・分類 |

**「AI はツールであり、人間がアカウンタビリティを持つ」** — アカウンタビリティの中身が「作業の管理」から「AI 出力を正しい方向に導く判断」へシフトしている。

## 新しいインタラクションモデル

### 従来: 直列的なハンドオフ

```
PM（戦略）→ PO（要件）→ SM（プロセス）→ 開発チーム → PjM（進捗管理）
```

### AI-DLC: 並列的なオーケストレーション

```
PM（AI Strategy Architect）
  ↕ 戦略 ↔ 仮説
PO（Value Orchestrator）
  ↕ スペック ↔ 検証
AI エージェント群（Claude Code + サブエージェント）
  ↕ 実装 ↔ ガードレール
SM（Agent Orchestration Coach）
  ↕ フロー ↔ ガバナンス
PjM（Delivery System Operator）
```

全役割が AI エージェントと直接インタラクションする。「AI は開発者だけが使うもの」という前提は崩壊している。
