# 見積もり精度を高める実践フレームワーク

## AI タスク分類マトリクス

各タスクを AI の得意・不得意で分類し、適用する AEF を決定する。

| 分類 | AI 適性 | AEF 目安 | 例 |
|---|---|---|---|
| **Tier 1: AI 完全自動化** | 高 | 60〜80% | 定型コード生成、テストコード、ドキュメント雛形 |
| **Tier 2: AI 支援＋人間判断** | 中 | 30〜50% | API/DB 設計、リファクタリング、コードレビュー |
| **Tier 3: 人間主導＋AI 補助** | 低 | 10〜20% | 要件ヒアリング、アーキテクチャ判断、セキュリティ設計 |
| **Tier 4: 人間専門** | なし | 0% | ステークホルダー調整、ビジネスルール確認、契約交渉 |

各チケットをこのマトリクスで分類することで、見積もり根拠が客観的かつ説明可能になる。

## コンフィデンス・スコアリング

一点見積もりではなく、**確信度付きの範囲見積もり**を採用する。

| スコア | 意味 | 対応 |
|---|---|---|
| 80〜100 | 過去に類似実績あり、高精度 | そのまま採用 |
| 50〜79 | 類似実績はあるが条件が異なる、中精度 | バッファ含み見積もり |
| 0〜49 | 前例なし、不確実性が高い | **人間の専門家による補正が必須**、リスクバッファ明示 |

クライアントには「確信度 50 未満の項目はリスクバッファを含む」と明示し、透明性を確保する。

-> コンフィデンス・スコアからリスク発生確率への定量変換ロジックは [risk-register.md](risk-register.md) を参照

## 過去実績ベースの予測モデル

AI 見積もりツールが過去のプロジェクトデータから学習し、新規プロジェクトの工数を予測する。

Anthropic の検証では、Claude によるタスク時間推定は人間の開発者自身の推定（Spearman 相関 ρ=0.50）に近い精度（ρ=0.44）を達成。**方向性の妥当な参考値**として活用可能。

### 実践アプローチ

1. 社内の過去プロジェクトデータ（見積もり vs 実績）をデータベース化
2. AI に NLP 解析させ、新規案件との類似度を算出
3. 類似プロジェクトの実績値をベースに初期見積もりを自動生成
4. 人間の PM/アーキテクトがコンテキストを加味して調整

## 見積もり支援の自動化

Claude Code に見積もり支援スキルを定義し、以下を自動化する：

1. **要件ドキュメント解析**：RFP やヒアリング議事録から機能リストを自動抽出
2. **タスク分類**：AI タスク分類マトリクスに基づき Tier 1〜4 に自動分類
3. **初期見積もり生成**：過去の類似プロジェクトデータと AEF を適用し工数レンジを算出
4. **リスクフラグ**：曖昧な要件や前例のない技術要素を検出、コンフィデンス・スコア付与
5. **見積もり書ドラフト生成**：クライアント提出用テンプレートに自動反映

従来 1〜2 週間の見積もり作業を **2〜3 日に短縮**しつつ、精度と説明可能性を向上。
