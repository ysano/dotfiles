## 手戻りコストと不信頼税の定量モデル

LLM の確率的な振る舞いに起因する「手戻り」の追加コストを定量化し、モデル選択の損益分岐点を算出する。

### 変数定義

| 変数 | 意味 |
|------|------|
| P_s | 1回の試行でタスクを完了する確率（成功率） |
| T | 成功に必要な平均ターン数 |
| I_i | i ターン目の平均入力トークン数（コンテキスト履歴含む） |
| O_i | i ターン目の平均出力トークン数 |
| C_in | 入力トークン単価（$/百万トークン） |
| C_out | 出力トークン単価（$/百万トークン） |
| alpha | リカバリー係数（失敗→修正の追加労力倍率） |

### 基本コストの計算

コンテキストはターンごとに履歴を蓄積するため、入力トークン数は線形に増加する。
i ターン目の入力を `I_i ≈ i × I_1` と近似すると:

```
C_base = Σ(i=1→T) [ I_i × C_in + O_i × C_out ] / 1,000,000
```

ターンが増えるほど入力コストが加速度的に増大する点が重要。

### 不信頼税を含む期待コスト

成功率 P_s の幾何分布に従い、成功までの期待試行回数は `1/P_s`:

```
E[Cost] = C_base × (1/P_s) × alpha
```

**不信頼税**（Unreliability Tax）:

```
Tax = E[Cost] - C_base = C_base × ((1/P_s) - 1) × alpha
```

### 成功率とコスト倍率の関係

| P_s（成功率） | 期待試行回数 | コスト倍率 |
|:---:|:---:|:---:|
| 90% | 1.1回 | 1.1倍 |
| 70% | 1.4回 | 1.4倍 |
| 50% | 2.0回 | 2.0倍 |
| 30% | 3.3回 | 3.3倍 |
| 20% | 5.0回 | 5.0倍 |

**洞察**: P_s が 50% → 20% に低下するとコストは 2.5倍に跳ね上がる。

### 損益分岐点分析（Break-Even）

2つのモデル A, B を比較する場合:

```
E[Cost_A] > E[Cost_B]  ⇔  C_base_A / P_s_A > C_base_B / P_s_B
```

**Haiku vs Sonnet の例（中程度のバグ修正）**:

| モデル | 基本コスト | P_s | 期待コスト |
|--------|-----------|:---:|-----------|
| Haiku | $0.02 | 40% | $0.05 |
| Sonnet | $0.15 | 85% | $0.18 |
| Opus | $0.75 | 95% | $0.79 |

この例では Haiku が最安だが、**人間介入コスト**を加算すると逆転する。

### 人間介入コストの加算

エージェントが N 回失敗した後に人間が介入する場合:

```
E[Cost_total] = E[Cost_token] + (1 - P_s)^N × H × t
```

- H: 人間の時給（例: $100/h）
- t: 介入に要する時間（例: 0.5h）
- (1 - P_s)^N: N 回連続で失敗する確率

P_s が低いモデルでは、人間介入のリスクが指数関数的に増大する。
**純粋なトークンコストだけでなく、人間介入率の最小化**が経済的合理性の核心。

### Thinking Mode の経済効果

Thinking Mode は出力トークンの一部を「思考」に費やす。一見コスト増だが:

**外部ループ（従来）**:
実装（出力課金）→ テスト失敗（入力課金）→ エラー読込（入力課金）→ 再実装（出力課金）
- 履歴蓄積により I_i が肥大化

**内部ループ（思考）**:
思考（出力課金）→ 自己修正（出力課金）→ 正解実装（出力課金）
- 外部コンテキストは肥大化しない

**判断基準**: Thinking Mode により P_s が十分に向上し、コンテキスト肥大化を回避できる場合、トータルではデフレ的（コスト削減）に作用する。複雑なタスクほど効果が大きい。

### 実務への適用

1. **P_s の事前推定**: NLCC（`nlcc-complexity.md`）で複雑性を評価し、P_s を概算
2. **閾値の設定**: 期待コスト倍率 2倍（P_s < 50%）を超えたら上位モデルへ切替
3. **定期的な実績レビュー**: 実際の試行回数を記録し、P_s の見積もりを校正
